{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-17T20:35:10.934338Z","iopub.execute_input":"2023-09-17T20:35:10.934803Z","iopub.status.idle":"2023-09-17T20:35:10.952571Z","shell.execute_reply.started":"2023-09-17T20:35:10.934766Z","shell.execute_reply":"2023-09-17T20:35:10.951297Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-17T20:35:11.391522Z","iopub.execute_input":"2023-09-17T20:35:11.391919Z","iopub.status.idle":"2023-09-17T20:35:11.407007Z","shell.execute_reply.started":"2023-09-17T20:35:11.391887Z","shell.execute_reply":"2023-09-17T20:35:11.405700Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T20:35:11.921051Z","iopub.execute_input":"2023-09-17T20:35:11.922217Z","iopub.status.idle":"2023-09-17T20:35:11.942084Z","shell.execute_reply.started":"2023-09-17T20:35:11.922162Z","shell.execute_reply":"2023-09-17T20:35:11.941253Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"parameter_list2 = ['Age','SibSp','Parch','Fare', 'Pclass', 'Survived', 'PassengerId']\nfor par in parameter_list2:\n    print('\\nstats for {}\\nmax :{}   min :{}\\naverage : {}\\nnum_nans : {}'.format(par, train_data[par].max(), train_data[par].min(), train_data[par].mean(),train_data[par].isna().astype(int).sum()))","metadata":{"execution":{"iopub.status.busy":"2023-09-17T20:35:12.399555Z","iopub.execute_input":"2023-09-17T20:35:12.400364Z","iopub.status.idle":"2023-09-17T20:35:12.413089Z","shell.execute_reply.started":"2023-09-17T20:35:12.400319Z","shell.execute_reply":"2023-09-17T20:35:12.411881Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"\nstats for Age\nmax :80.0   min :0.42\naverage : 29.69911764705882\nnum_nans : 177\n\nstats for SibSp\nmax :8   min :0\naverage : 0.5230078563411896\nnum_nans : 0\n\nstats for Parch\nmax :6   min :0\naverage : 0.38159371492704824\nnum_nans : 0\n\nstats for Fare\nmax :512.3292   min :0.0\naverage : 32.204207968574636\nnum_nans : 0\n\nstats for Pclass\nmax :3   min :1\naverage : 2.308641975308642\nnum_nans : 0\n\nstats for Survived\nmax :1   min :0\naverage : 0.3838383838383838\nnum_nans : 0\n\nstats for PassengerId\nmax :891   min :1\naverage : 446.0\nnum_nans : 0\n","output_type":"stream"}]},{"cell_type":"code","source":"#numerical features attempt (ideas: try to use regression to predict missing age values,)\n#numerical features are 'Pclass','Sex','Age','SibSp','Parch','Fare'\ntrain_data1 = train_data.copy()\ntrain_data1.loc[train_data1['Age'].isna(),'Age'] = train_data1['Age'].median()\ntrain_data1['Sex'] = (train_data1['Sex'] == 'female').astype(int)\ntrain_data1['Sex'] = train_data1['Sex']/train_data1['Sex'].max()\ntrain_data1['Age'] = train_data1['Age']/train_data1['Age'].max()\ntrain_data1['SibSp'] = train_data1['SibSp']/train_data1['SibSp'].max()\ntrain_data1['Parch'] = train_data1['Parch']/train_data1['Parch'].max()\ntrain_data1['Fare'] = train_data1['Fare']/train_data1['Fare'].max()\ntrain_data1['Pclass'] = train_data1['Pclass']/train_data1['Pclass'].max()\n\n\nX = train_data1[['Pclass','Sex','Age','SibSp','Parch','Fare']].copy()\nY = train_data1['Survived'].copy()\n\n\n\nparameter_list = ['Pclass','Sex','Age','SibSp','Parch','Fare']\n\nfor par in parameter_list:\n    print('Num nans in {} : {}'.format(par, X[par].isna().astype(int).sum()))\nprint('Num nans in Y : {}'.format( Y.isna().astype(int).sum()))","metadata":{"execution":{"iopub.status.busy":"2023-09-17T20:35:15.416735Z","iopub.execute_input":"2023-09-17T20:35:15.417145Z","iopub.status.idle":"2023-09-17T20:35:15.439600Z","shell.execute_reply.started":"2023-09-17T20:35:15.417114Z","shell.execute_reply":"2023-09-17T20:35:15.438399Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Num nans in Pclass : 0\nNum nans in Sex : 0\nNum nans in Age : 0\nNum nans in SibSp : 0\nNum nans in Parch : 0\nNum nans in Fare : 0\nNum nans in Y : 0\n","output_type":"stream"}]},{"cell_type":"code","source":"#idea introduce min threshold for a split to be valid\ndef DT_split(parameters,data,response_parameter):\n        split_error_dict = {}\n        split_impossible = True\n        for param in parameters:\n            temp_values = data[param].unique()\n            temp_values.sort()\n            if len(temp_values) > 1:\n                split_impossible = False\n                if len(temp_values) > 2:\n                    for val in temp_values[1:-1]:\n                        sum1 = (data[data[param] <= val][response_parameter].mean() - data[data[param] <= val][response_parameter])\n                        sum1 = sum1*sum1\n                        sum1 = sum1.sum()\n                        sum2 = (data[data[param] > val][response_parameter].mean() - data[data[param] > val][response_parameter])\n                        sum2 = sum2*sum2\n                        sum2 = sum2.sum()\n                        split_error_dict['{}-{}'.format(param,val)] =  sum1 + sum2\n                else:\n                    sum1 = (data[data[param] == temp_values[0]][response_parameter].mean() - data[data[param] == temp_values[0]][response_parameter])\n                    sum1 = sum1*sum1\n                    sum1 = sum1.sum()\n                    sum2 = (data[data[param] == temp_values[1]][response_parameter].mean() - data[data[param] == temp_values[1]][response_parameter])\n                    sum2 = sum2*sum2\n                    sum2 = sum2.sum()\n                    split_error_dict['{}-bi'.format(param)] =  sum1 + sum2\n        if split_impossible:\n            return [-1,'no_possible_split']\n        else:\n            #print(split_error_dict)\n            best_split = min(split_error_dict , key = split_error_dict.get)\n            return [split_error_dict[best_split],best_split]","metadata":{"execution":{"iopub.status.busy":"2023-09-17T21:17:48.140476Z","iopub.execute_input":"2023-09-17T21:17:48.141025Z","iopub.status.idle":"2023-09-17T21:17:48.155091Z","shell.execute_reply.started":"2023-09-17T21:17:48.140991Z","shell.execute_reply":"2023-09-17T21:17:48.153773Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"def generate_tree(parameters,data,response_parameter,max_depth):\n    D_tree_leaves = {'root': data}\n    max_depth_notreached = True\n    while max_depth_notreached:\n        possible_splits = {}\n        for key in D_tree_leaves:\n            possible_split_temp = DT_split(parameters,D_tree_leaves[key],response_parameter)\n            if possible_split_temp[0]>0:\n                possible_splits[key] = possible_split_temp\n        #print(possible_splits)\n        if len(possible_splits) > 0:\n            best_split = min(possible_splits , key = possible_splits.get)\n            best_split_info = possible_splits[best_split][1]\n            best_split_info_temp = best_split_info.split('-')\n            if best_split_info_temp[1] == 'bi':\n                temp_values = D_tree_leaves[best_split][best_split_info_temp[0]].unique()\n                temp_values.sort()\n                D_tree_leaves[best_split+'/'+possible_splits[best_split][1]+'_l'] = D_tree_leaves[best_split][D_tree_leaves[best_split][best_split_info_temp[0]] == float(temp_values[0])]\n                D_tree_leaves[best_split+'/'+possible_splits[best_split][1]+'_r'] = D_tree_leaves[best_split][D_tree_leaves[best_split][best_split_info_temp[0]] == float(temp_values[1])]\n                del D_tree_leaves[best_split]\n            else:\n                D_tree_leaves[best_split+'/'+possible_splits[best_split][1]+'_l'] = D_tree_leaves[best_split][D_tree_leaves[best_split][best_split_info_temp[0]] <= float(best_split_info_temp[1])]\n                D_tree_leaves[best_split+'/'+possible_splits[best_split][1]+'_r'] = D_tree_leaves[best_split][D_tree_leaves[best_split][best_split_info_temp[0]] > float(best_split_info_temp[1])]\n                del D_tree_leaves[best_split]\n        else:\n            print('max_depth cant be reached because there are no more possible splits')\n            max_depth_notreached = False\n            \n        for key in D_tree_leaves:\n            temp_key = key.split('/')\n            if len(temp_key) >= max_depth:\n                max_depth_notreached = False\n    return D_tree_leaves\n        ","metadata":{"execution":{"iopub.status.busy":"2023-09-17T21:21:06.821235Z","iopub.execute_input":"2023-09-17T21:21:06.822072Z","iopub.status.idle":"2023-09-17T21:21:06.832681Z","shell.execute_reply.started":"2023-09-17T21:21:06.822039Z","shell.execute_reply":"2023-09-17T21:21:06.831596Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"test = generate_tree(['Pclass','Sex','Age','SibSp','Parch','Fare'], train_data1, 'Survived',5)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T21:28:57.485356Z","iopub.execute_input":"2023-09-17T21:28:57.486712Z","iopub.status.idle":"2023-09-17T21:29:03.768280Z","shell.execute_reply.started":"2023-09-17T21:28:57.486650Z","shell.execute_reply":"2023-09-17T21:29:03.767354Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"test.keys()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T21:29:03.769993Z","iopub.execute_input":"2023-09-17T21:29:03.770360Z","iopub.status.idle":"2023-09-17T21:29:03.778394Z","shell.execute_reply.started":"2023-09-17T21:29:03.770329Z","shell.execute_reply":"2023-09-17T21:29:03.776825Z"},"trusted":true},"execution_count":120,"outputs":[{"execution_count":120,"output_type":"execute_result","data":{"text/plain":"dict_keys(['root/Sex-bi_l', 'root/Sex-bi_r/Pclass-0.6666666666666666_r', 'root/Sex-bi_r/Pclass-0.6666666666666666_l/Fare-0.05604306762136532_l', 'root/Sex-bi_r/Pclass-0.6666666666666666_l/Fare-0.05604306762136532_r/Age-0.0375_l', 'root/Sex-bi_r/Pclass-0.6666666666666666_l/Fare-0.05604306762136532_r/Age-0.0375_r'])"},"metadata":{}}]}]}
